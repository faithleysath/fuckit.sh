import { env_var_get, echo_error, echo_warning, echo_info, echo_success, input_prompt, input_confirm } from "std/env"
import { request_llm } from "../utils/llm.ab"
import { get_core_prompt, get_python_tool_prompt } from "./prompt.ab"
import { check_llm_output } from "../utils/security.ab"
import { get_python_info } from "../utils/system.ab"
import { split, replace } from "std/text"
import { llm_config } from "./config.ab"

pub fun start_chat_session(initial_prompt: [Text]): Null {
    // Step 1: Load configuration
    let config = llm_config() failed {
        echo_error(trust env_var_get("MSG_ERR_LLM_CONFIG_MISSING"))
        exit 1
    }
    let base_url = config[0]
    let api_key = config[1]
    let model_name = config[2]

    if model_name == "" {
        echo_error(trust env_var_get("MSG_ERR_LLM_MODEL_MISSING"))
        exit 1
    }

    // Step 2: Initialize histories and system prompt
    let user_history = [Text]
    let assistant_history = [Text]
    let system_prompt = get_core_prompt()

    // Check for python and enhance prompt if available
    let python_info = get_python_info()
    if len(python_info) > 0 {
        let python_details = split(python_info[0], " ")
        let python_cmd = python_details[0]
        let python_version = python_details[1]
        system_prompt += get_python_tool_prompt(python_cmd, python_version)
    }

    // Step 3: Start the interactive chat loop
    let current_user_prompt = "{initial_prompt}"
    loop {
        user_history += [current_user_prompt]

        echo_info(trust env_var_get("MSG_ASSISTANT_THINKING"))
        let assistant_response = request_llm(base_url, model_name, api_key, system_prompt, user_history, assistant_history) failed {
            echo_warning(trust env_var_get("MSG_ERR_LLM_FAILED"))
            // Ask user if they want to retry
            if input_confirm(trust env_var_get("MSG_PROMPT_RETRY"), true) {
                // Remove the last failed prompt from history before retrying
                user_history = user_history[0..len(user_history)-1]
                continue
            } else {
                exit 1
            }
        }

        assistant_history += [assistant_response]

        // Step 4: Security check and execution
        let is_safe = check_llm_output(assistant_response)

        let should_execute = false
        if is_safe {
            should_execute = true
            echo_success(trust env_var_get("MSG_SECURITY_CHECK_PASSED"))
        } else {
            echo assistant_response
            echo_warning(trust env_var_get("MSG_SECURITY_CHECK_FAILED"))
            should_execute = input_confirm(trust env_var_get("MSG_PROMPT_EXECUTE_ANYWAY"), false)
        }
        let scode = 0
        let execution_context = ""
        if should_execute {
            if not is_safe {
                echo_info(trust env_var_get("MSG_EXEC_COUNTDOWN"))
                trust $ sleep 1 $
            }
            scode = 0
            let output = $ set -o pipefail; bash -c "set -e; set -o pipefail;\n{assistant_response}" 2>&1 | tee /dev/tty $ failed {
                scode = status
                if status == 201 {
                    echo_info(trust env_var_get("MSG_SESSION_ENDED_BY_ASSISTANT"))
                    exit 0
                }
                if status == 202 {
                    echo_info(trust env_var_get("MSG_SESSION_SUGGEST_END"))
                    if input_confirm(trust env_var_get("MSG_PROMPT_END_SESSION"), true) {
                        exit 0
                    }
                }
                if status == 203 {
                    echo_info(trust env_var_get("MSG_ASSISTANT_CONTINUE"))
                    // Skip user input and continue the loop
                } else {
                    let tpl = trust env_var_get("MSG_ERR_EXEC_FAILED")
                    echo_warning(replace(tpl, "\{status}", "{status}"))
                }
            }
            if scode == 0:
                echo_success(trust env_var_get("MSG_EXEC_SUCCESS"))
            if is_safe:
                execution_context = trust env_var_get("MSG_CONTEXT_EXEC_SUCCESS")
            else:
                let tpl = trust env_var_get("MSG_CONTEXT_EXEC_FAIL")
                execution_context = replace(replace(tpl, "\{scode}", "{scode}"), "\{output}", output)
        } else {
            echo_warning(trust env_var_get("MSG_EXEC_SKIPPED"))
            execution_context = trust env_var_get("MSG_CONTEXT_EXEC_SKIPPED")
        }

        // Step 5: Get next user input or continue automatically
        if scode == 203 {
            current_user_prompt = "{execution_context}\n\nUser's next instruction: [AUTO-CONTINUE]"
            continue
        }

        let next_user_input = ""
        loop {
            next_user_input = input_prompt(trust env_var_get("MSG_PROMPT_USER"))
            if next_user_input != "" {
                break
            }
        }
        if next_user_input == "exit" or next_user_input == "quit" {
            break
        }
        current_user_prompt = "{execution_context}\n\nUser's next instruction: {next_user_input}"
    }
    echo_info(trust env_var_get("MSG_SESSION_ENDED_BY_USER"))
}
